{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_iters = 5 将所有的样本至少看五遍\n",
    "def fit_sgd(self,X_train,y_train,n_iters = 5,t0 = 5,t1 = 50):\n",
    "        \"\"\"根据训练数据集X_train, y_train, 使用梯度下降法训练Linear Regression模型\"\"\"\n",
    "        assert X_train.shape[0] == y_train.shape[0], \\\n",
    "            \"the size of X_train must be equal to the size of y_train\"\n",
    "        assert n_iters >= 1    \n",
    "        \n",
    "        def dJ_sgd(theta,X_b,y_i):\n",
    "            return X_b_i * (X_b_i.dot(theta) - y_i) * 2.\n",
    "        \n",
    "        #下面不写t0 t1 应该也不会报错哇?\n",
    "        def sgd(X_b,y,initial_theta,n_iters,t0 = 5, t1 = 50):\n",
    "            \n",
    "            def learning_rate(t):\n",
    "                return t0/(t + t1)\n",
    "            \n",
    "            theta = initial_theta\n",
    "            # 为什么需要m? 接下去计算index\n",
    "            m = len(X_b)\n",
    "        \n",
    "            # 在指定次数中循环,每次循环,都随机的把所有样本看一遍.\n",
    "            # 这样做,是防止,直接取随机数,有些样本没有取到.\n",
    "            for cur_iter in range(n_iters):\n",
    "                indexes = np.random.permutation(m)\n",
    "                #打乱了X_b,y的样本排列顺序,保证所有的样本都能够取到.\n",
    "                X_b_new = X_b[indexes]\n",
    "                y_new = y[indexes]\n",
    "                #考虑每一个样本的梯度.\n",
    "                for i in range(m):\n",
    "                    gradient = dJ_sgd(theta,X_b_new[i],y_new[i])\n",
    "                    #注意学习率,考虑\n",
    "                    theta = theta - learning_rate(cur_iter *m + i ) * gradient\n",
    "                    \n",
    "            return theta\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用我们自己的SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 100000\n",
    "\n",
    "x = np.random.normal(size = m)\n",
    "X = x.reshape(-1,1)\n",
    "y = 4.*x  + 3 + np.random.normal(0,3,size = m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mymodule.LinearRegression  import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_sgd = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_sgd.fit_sgd(X,y,n_iters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.00419755])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_sgd.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0183394805517363"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_sgd.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 真实使用我们自己的SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn  import datasets\n",
    "\n",
    "boston  = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X = X[y<50.0]\n",
    "y = y[y<50.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from mymodule.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,seed = 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standrdScaler = StandardScaler()\n",
    "standrdScaler.fit(X_train,y_train)\n",
    "X_train_standard = standrdScaler.transform(X_train)\n",
    "X_test_standard = standrdScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.06 ms, sys: 3.33 ms, total: 12.4 ms\n",
      "Wall time: 9.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78651716204682975"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_sgd_boston = LinearRegression()\n",
    "%time reg_sgd_boston.fit_sgd(X_train_standard,y_train,n_iters=2)\n",
    "reg_sgd_boston.score(X_test_standard,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 132 ms, sys: 2.72 ms, total: 135 ms\n",
      "Wall time: 133 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8074538468965633"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time reg_sgd_boston.fit_sgd(X_train_standard,y_train,n_iters=50)\n",
    "reg_sgd_boston.score(X_test_standard,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 266 ms, sys: 5.4 ms, total: 271 ms\n",
      "Wall time: 279 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81086710549749141"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time reg_sgd_boston.fit_sgd(X_train_standard,y_train,n_iters=100)\n",
    "reg_sgd_boston.score(X_test_standard,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用scikit-learn进行随机梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.7 ms, sys: 1.17 ms, total: 2.88 ms\n",
      "Wall time: 1.71 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaruihan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80691391167110316"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_sgd = SGDRegressor()\n",
    "%time reg_sgd.fit(X_train_standard,y_train)\n",
    "reg_sgd.score(X_test_standard,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.06 ms, sys: 3.04 ms, total: 12.1 ms\n",
      "Wall time: 8.27 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaruihan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81329574351286338"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_sgd = SGDRegressor(n_iter = 100)\n",
    "%time reg_sgd.fit(X_train_standard,y_train)\n",
    "reg_sgd.score(X_test_standard,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
